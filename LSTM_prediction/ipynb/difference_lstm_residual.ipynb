{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n53\nerr: 2.80674703937\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\\\gejun\\\\Documents\\\\Git\\\\YuEbaoPrediction\\\\LSTM_prediction\n",
    "\n",
    "'''\n",
    "申购的lstm\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import keras.models\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# X is the number of passengers at a given time (t) and Y is the number of passengers at the next time (t + 1).\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 差分操作,d代表差分序列，比如[1,1,1]可以代表3阶差分。  [12,1]可以代表第一次差分偏移量是12，第二次差分偏移量是1\n",
    "def diff_ts(ts, d):\n",
    "    global shift_ts_list\n",
    "    #  动态预测第二日的值时所需要的差分序列\n",
    "    global last_data_shift_list #这个序列在恢复过程中需要用到\n",
    "    shift_ts_list = []\n",
    "    last_data_shift_list = []\n",
    "    tmp_ts = ts\n",
    "    for i in d:\n",
    "        last_data_shift_list.append(tmp_ts[-i])\n",
    "        print (last_data_shift_list)\n",
    "        shift_ts = tmp_ts.shift(i)\n",
    "        shift_ts_list.append(shift_ts)\n",
    "        tmp_ts = tmp_ts - shift_ts\n",
    "    tmp_ts.dropna(inplace=True)\n",
    "    return tmp_ts\n",
    "\n",
    "def predict_diff_recover(predict_value, d):\n",
    "    if isinstance(predict_value, float):\n",
    "        tmp_data = predict_value\n",
    "        for i in range(len(d)):\n",
    "            tmp_data = tmp_data + last_data_shift_list[-i-1]\n",
    "    elif isinstance(predict_value, np.ndarray):\n",
    "        tmp_data = predict_value[0]\n",
    "        for i in range(len(d)):\n",
    "            tmp_data = tmp_data + last_data_shift_list[-i-1]\n",
    "    else:\n",
    "        tmp_data = predict_value\n",
    "        for i in range(len(d)):\n",
    "            try:\n",
    "                tmp_data = tmp_data.add(shift_ts_list[-i-1])\n",
    "            except:\n",
    "                raise ValueError('What you input is not pd.Series type!')\n",
    "        tmp_data.dropna(inplace=True)\n",
    "    return tmp_data\n",
    "\n",
    "def test_stationarity(timeseries):\n",
    "    # Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=30)\n",
    "    rolstd = pd.rolling_std(timeseries, window=30)\n",
    "\n",
    "    # Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue', label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "dataframe = read_csv('../file/group_by_date.csv', index_col='report_date', parse_dates=[0], engine='python')\n",
    "dataframe = dataframe[244:]\n",
    "purchase_original_ts = dataframe['total_purchase_amt']\n",
    "diff1_purchase_original = diff_ts(purchase_original_ts, [1])\n",
    "# dataset = np.array(diff1_purchase_original.values)\n",
    "dataset = diff1_purchase_original.values\n",
    "dataset = dataset.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# use this function to prepare the train and test datasets for modeling\n",
    "look_back = 7\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "myfile = os.path.exists(\"lstm.model\")\n",
    "if myfile:\n",
    "    print(\"ssss\")\n",
    "else:\n",
    "    model_prob = model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n53\nerr: 2.80674703937\n"
     ]
    }
   ],
   "source": [
    "print(len(testY[0]))\n",
    "print(len(testPredict[:,0]))\n",
    "test = testY[0].reshape(-1, 1)\n",
    "errs = mape(test,testPredict[:,0])\n",
    "print(\"err:\",errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n53\nerr: 2.80674703937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "errs = mape(testY[0],testPredict[:,0])\n",
    "print(\"err:\",errs)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "trainData = pd.DataFrame({'trainpredict':trainPredict[:,0],'actual':trainY[0]})\n",
    "testData = pd.DataFrame({'testpredict':testPredict[:,0],'actual':testY[0]})\n",
    "trainData.to_csv(\"../file/3_8_diff_purchase_train.csv\")\n",
    "testData.to_csv(\"../file/3_8_diff_purchase_test.csv\")\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "test_df = read_csv('../file/3_8_diff_purchase_test.csv', engine='python')\n",
    "residual = test_df['actual'] - test_df['testpredict']\n",
    "residual.describe()\n",
    "mean = residual.mean()\n",
    "mean_test_predict = test_df['testpredict'] + mean\n",
    "mean_residual = test_df['actual'] - mean_test_predict\n",
    "mean_residual.describe()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "mean_residual.plot()\n",
    "plt.show()\n",
    "\n",
    "# 直方图 是否正态分布\n",
    "mean_residual.hist()\n",
    "plt.show()\n",
    "\n",
    "# autocorrelation\n",
    "plot_acf(mean_residual, ax=plt.gca(), lags=30)\n",
    "plt.show()\n",
    "\n",
    "# LBQ 检验\n",
    "from statsmodels.stats import diagnostic\n",
    "diagnostic.acorr_ljungbox(mean_residual, lags=None, boxpierce=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
