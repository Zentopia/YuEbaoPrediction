{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\graduation\\YuEbaoPrediction\\ARIMA_prediction\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\\\graduation\\\\YuEbaoPrediction\\\\ARIMA_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import numpy as np\n",
    "import sys\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "def err(true,predicted):\n",
    "    err = 0\n",
    "    for i in range(len(true)):\n",
    "        tmp = (true[i]-predicted[i])/true[i]\n",
    "        err += tmp*tmp\n",
    "    standard_err = np.sqrt(err/len(true))\n",
    "    return standard_err\n",
    "# 差分操作,d代表差分序列，比如[1,1,1]可以代表3阶差分。  [12,1]可以代表第一次差分偏移量是12，第二次差分偏移量是1\n",
    "def diff_ts(ts, d):\n",
    "    global shift_ts_list\n",
    "    #  动态预测第二日的值时所需要的差分序列\n",
    "    global last_data_shift_list #这个序列在恢复过程中需要用到\n",
    "    shift_ts_list = []\n",
    "    last_data_shift_list = []\n",
    "    tmp_ts = ts\n",
    "    for i in d:\n",
    "        last_data_shift_list.append(tmp_ts[-i])\n",
    "        print (last_data_shift_list)\n",
    "        shift_ts = tmp_ts.shift(i)\n",
    "        shift_ts_list.append(shift_ts)\n",
    "        tmp_ts = tmp_ts - shift_ts\n",
    "    tmp_ts.dropna(inplace=True)\n",
    "    return tmp_ts\n",
    "\n",
    "def predict_diff_recover(predict_value, d):\n",
    "    if isinstance(predict_value, float):\n",
    "        tmp_data = predict_value\n",
    "        for i in range(len(d)):\n",
    "            tmp_data = tmp_data + last_data_shift_list[-i-1]\n",
    "    elif isinstance(predict_value, np.ndarray):\n",
    "        tmp_data = predict_value[0]\n",
    "        for i in range(len(d)):\n",
    "            tmp_data = tmp_data + last_data_shift_list[-i-1]\n",
    "    else:\n",
    "        tmp_data = predict_value\n",
    "        for i in range(len(d)):\n",
    "            try:\n",
    "                tmp_data = tmp_data.add(shift_ts_list[-i-1])\n",
    "            except:\n",
    "                raise ValueError('What you input is not pd.Series type!')\n",
    "        tmp_data.dropna(inplace=True)\n",
    "    return tmp_data\n",
    "\n",
    "def test_stationarity(timeseries):\n",
    "    # Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=30)\n",
    "    rolstd = pd.rolling_std(timeseries, window=30)\n",
    "\n",
    "    # Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue', label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "\n",
    "def proper_model(ts_log_diff, maxLag):\n",
    "    best_p = 0\n",
    "    best_q = 0\n",
    "    best_bic = sys.maxsize\n",
    "    best_model=None\n",
    "    for p in np.arange(maxLag):\n",
    "        for q in np.arange(maxLag):\n",
    "            model = ARMA(ts_log_diff, order=(p, q))\n",
    "            try:\n",
    "                results_ARMA = model.fit(disp=-1)\n",
    "            except:\n",
    "                continue\n",
    "            bic = results_ARMA.bic\n",
    "            print (bic, best_bic)\n",
    "            if bic < best_bic:\n",
    "                best_p = p\n",
    "                best_q = q\n",
    "                best_bic = bic\n",
    "                best_model = results_ARMA\n",
    "    print(best_p,best_q,best_model)\n",
    "\n",
    "df = pd.read_csv('../file/user_balance_table_all.csv', index_col='user_id', names=['user_id', 'report_date', 'tBalance', 'yBalance', 'total_purchase_amt', 'direct_purchase_amt', 'purchase_bal_amt', 'purchase_bank_amt', 'total_redeem_amt', 'consume_amt', 'transfer_amt', 'tftobal_amt', 'tftocard_amt', 'share_amt', 'category1', 'category2', 'category3', 'category4'\n",
    "], parse_dates=[1])\n",
    "\n",
    "df['report_date'] = pd.to_datetime(df['report_date'], errors='coerce')\n",
    "\n",
    "labels = ['tBalance', 'yBalance', 'total_purchase_amt', 'direct_purchase_amt', 'purchase_bal_amt', 'purchase_bank_amt', 'total_redeem_amt', 'consume_amt', 'transfer_amt', 'tftobal_amt', 'tftocard_amt', 'share_amt']\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    df[label] = pd.to_numeric(df[label], errors='coerce')\n",
    "\n",
    "df = df.groupby('report_date').sum()\n",
    "total_redeem_original = df['total_redeem_amt']\n",
    "# ts = ts['2014-04-01':'2014-06-30']\n",
    "total_redeem_original\n",
    "\n",
    "\n",
    "\n",
    "# print('原数据ADF')\n",
    "# test_stationarity(ts)\n",
    "\n",
    "total_redeem_original.plot()\n",
    "plt.title('Total Redeem')\n",
    "plt.show()\n",
    "\n",
    "#一阶差分\n",
    "diff_1 = diff_ts(total_redeem_original, [1])\n",
    "diff_1.plot()\n",
    "# plt.title('Total purchase first difference')\n",
    "plt.title('Total redeem first difference')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.axhline(y=-1.96/np.sqrt(len(total_redeem_original)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(total_redeem_original)), linestyle='--', color='gray')\n",
    "plot_acf(total_redeem_original, ax=plt.gca(), lags=60)\n",
    "plt.show()\n",
    "\n",
    "plt.axhline(y=-1.96/np.sqrt(len(total_redeem_original)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(total_redeem_original)), linestyle='--', color='gray')\n",
    "plot_pacf(total_redeem_original, ax=plt.gca(), lags=60)\n",
    "plt.show()\n",
    "\n",
    "diff_1 = diff_ts(total_redeem_original, [1])\n",
    "\n",
    "print('一阶差分数据ADF')\n",
    "test_stationarity(diff_1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axhline(y=-1.96/np.sqrt(len(diff_1)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(diff_1)),linestyle='--',color='gray')\n",
    "plot_acf(diff_1, ax=plt.gca(), lags=60)\n",
    "plt.show()\n",
    "\n",
    "plt.axhline(y=-1.96/np.sqrt(len(diff_1)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(diff_1)),linestyle='--',color='gray')\n",
    "plot_pacf(diff_1, ax=plt.gca(), lags=60)\n",
    "plt.show()\n",
    "\n",
    "rol_mean = total_redeem_original.rolling(window=7).mean()\n",
    "rol_mean.dropna(inplace=True)\n",
    "\n",
    "rol_mean.plot()\n",
    "plt.title('Rolling Mean')\n",
    "plt.show()\n",
    "\n",
    "ts_diff_1 = diff_ts(rol_mean, [1])\n",
    "\n",
    "ts_diff_1.plot()\n",
    "plt.title('First Difference')\n",
    "plt.show()\n",
    "\n",
    "print('移动平均并差分后ADF')\n",
    "test_stationarity(ts_diff_1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axhline(y=-1.96/np.sqrt(len(ts_diff_1)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(ts_diff_1)),linestyle='--',color='gray')\n",
    "plot_acf(ts_diff_1, ax=plt.gca(), lags=60)\n",
    "plt.show()\n",
    "\n",
    "plt.axhline(y=-1.96/np.sqrt(len(ts_diff_1)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(ts_diff_1)),linestyle='--',color='gray')\n",
    "plot_pacf(ts_diff_1, ax=plt.gca(), lags=60)\n",
    "plt.show()\n",
    "\n",
    "# proper_model(ts_diff_1, 10)\n",
    "\n",
    "model = ARMA(ts_diff_1, order=(1, 8))\n",
    "result_arma = model.fit(disp=-1, method='css')\n",
    "\n",
    "predict_ts = result_arma.predict()\n",
    "\n",
    "predict_ts.plot(label='predicted')\n",
    "ts_diff_1.plot(label='original')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "recovery_diff_1 = predict_diff_recover(predict_ts, [1])\n",
    "recovery_diff_1.plot()\n",
    "plt.show()\n",
    "\n",
    "rol_sum = total_redeem_original.rolling(window=6).sum()\n",
    "total_redeem_prediction = recovery_diff_1 * 7 - rol_sum.shift(1)\n",
    "\n",
    "total_redeem_prediction.plot(label='predicted')\n",
    "total_redeem_original.plot(label='original')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_redeem_residual = total_redeem_original - total_redeem_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_redeem_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_redeem_residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_redeem_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_redeem_residual_values = total_redeem_residual.values[8:]\n",
    "total_redeem_residual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df[8:]\n",
    "df['total_redeem_amt'] = total_redeem_residual_values\n",
    "df.to_csv('../file/hybrid_total_redeem.csv')\n",
    "# print(total_redeem_residual_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "赎回的lstm\n",
    "'''\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import keras.models\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "\n",
    "# X is the number of passengers at a given time (t) and Y is the number of passengers at the next time (t + 1).\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset_X, dataset_Y, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    dataX = dataset_X[0:len(dataset_Y)-look_back-1]\n",
    "    for i in range(len(dataset_Y)-look_back-1):\n",
    "        dataY.append(dataset_Y[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "# # load the dataset\n",
    "# dataframe = read_csv('./file/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "# dataset = dataframe.values\n",
    "# dataset = dataset.astype('float32')\n",
    "# plt.plot(dataset)\n",
    "# plt.show()\n",
    "\n",
    "dataframe = read_csv('../file/hybrid_total_redeem.csv', usecols=[5], engine='python', skipfooter=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "\n",
    "dataframe_mulfeature = read_csv('../file/hybrid_total_redeem.csv', usecols=[1,2,3,4,5,6,7,8,9,10,11,12], engine='python', skipfooter=3)\n",
    "dataset_mulfeature = dataframe_mulfeature.values\n",
    "dataset_mulfeature = dataset_mulfeature.astype('float64')\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset_mulfeature = scaler2.fit_transform(dataset_mulfeature)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train_x, test_x = dataset_mulfeature[0:train_size,:], dataset_mulfeature[train_size:len(dataset),:]\n",
    "train_y,test_y = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# use this function to prepare the train and test datasets for modeling\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train_x,train_y, look_back)\n",
    "testX, testY = create_dataset(test_x,test_y, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "print(\"trainX\",trainX.shape)\n",
    "print(\"trainY\",trainY.shape)\n",
    "print(\"testX\",testX.shape)\n",
    "print(\"testY\",testY.shape)\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1, 12)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "myfile = os.path.exists(\"lstm.model\")\n",
    "if myfile:\n",
    "    print(\"ssss\")\n",
    "else:\n",
    "    model_prob = model.fit(trainX, trainY, epochs=105, batch_size=1, verbose=2)\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#     joblib.dump(model_prob, \"lstm.model\")\n",
    "# clf = joblib.load(\"lstm.model\")\n",
    "# make predictions\n",
    "# trainPredict = clf.predict(trainX)\n",
    "# testPredict = clf.predict(testX)\n",
    "\n",
    "# invert predictions\n",
    "# trainPredict = scaler.inverse_transform(trainPredict)\n",
    "# trainY = scaler.inverse_transform([trainY])\n",
    "# testPredict = scaler.inverse_transform(testPredict)\n",
    "# testY = scaler.inverse_transform([testY])\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def err(true,predicted):\n",
    "    err = 0\n",
    "    for i in range(len(true)):\n",
    "        tmp = (true[i]-predicted[i])/true[i]\n",
    "        err += tmp*tmp\n",
    "    standard_err = np.sqrt(err/len(true))\n",
    "    return standard_err\n",
    "errs = err(testY[0],testPredict[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01801768],\n       [ 0.02215224],\n       [ 0.0363741 ],\n       [ 0.0258545 ],\n       [ 0.00562886],\n       [ 0.01355051],\n       [ 0.04067867],\n       [ 0.04332599],\n       [ 0.02034658],\n       [ 0.01525825],\n       [ 0.02529775],\n       [ 0.0112185 ],\n       [ 0.01196664],\n       [ 0.03249659],\n       [ 0.05129684],\n       [ 0.04096348],\n       [ 0.05054262],\n       [ 0.03702505],\n       [ 0.00775394],\n       [ 0.02802087],\n       [ 0.04637075],\n       [ 0.0399537 ],\n       [ 0.04747845],\n       [ 0.04619858],\n       [ 0.02991917],\n       [ 0.01240763],\n       [ 0.03808526],\n       [ 0.03584159],\n       [ 0.04352789],\n       [ 0.03611996],\n       [ 0.03673893],\n       [ 0.02496932],\n       [ 0.0113477 ],\n       [ 0.04846051],\n       [ 0.08993117],\n       [ 0.04123268],\n       [ 0.02188664],\n       [ 0.03451375],\n       [ 0.03373196],\n       [ 0.00820099],\n       [ 0.05289083],\n       [ 0.10550265],\n       [ 0.0464791 ],\n       [ 0.0299901 ],\n       [ 0.08415493],\n       [ 0.0296611 ],\n       [ 0.03655219],\n       [ 0.03542517],\n       [ 0.06859438],\n       [ 0.03750997],\n       [ 0.03891868],\n       [ 0.03987358],\n       [ 0.04939329],\n       [ 0.04003028],\n       [ 0.04915893],\n       [ 0.13908143],\n       [ 0.07496121],\n       [ 0.02481495],\n       [ 0.0304955 ],\n       [ 0.03066148],\n       [ 0.02555887],\n       [ 0.03057962],\n       [ 0.04172237],\n       [ 0.08996667],\n       [ 0.09451905],\n       [ 0.06222421],\n       [ 0.0654684 ],\n       [ 0.02223939],\n       [ 0.02871074],\n       [ 0.1611538 ],\n       [ 0.07033273],\n       [ 0.03491171],\n       [ 0.01562881],\n       [ 0.01944063],\n       [ 0.02373552],\n       [ 0.06106466],\n       [ 0.0474058 ],\n       [ 0.06821977],\n       [ 0.03951341],\n       [ 0.06230063],\n       [ 0.0340851 ],\n       [ 0.03178679],\n       [ 0.02588032],\n       [ 0.01946664],\n       [ 0.00961961],\n       [ 0.00155507],\n       [ 0.        ],\n       [ 0.01042583],\n       [ 0.01729268],\n       [ 0.03044309],\n       [ 0.03476878],\n       [ 0.10597591],\n       [ 0.06626722],\n       [ 0.06590523],\n       [ 0.07714987],\n       [ 0.07632187],\n       [ 0.06489394],\n       [ 0.12780981],\n       [ 0.08035687],\n       [ 0.09654014],\n       [ 0.08192836],\n       [ 0.09355807],\n       [ 0.04570227],\n       [ 0.03998252],\n       [ 0.10191933],\n       [ 0.14401521],\n       [ 0.10198114],\n       [ 0.06310049],\n       [ 0.06352611],\n       [ 0.04844465],\n       [ 0.06148   ],\n       [ 0.12739715],\n       [ 0.09766917],\n       [ 0.10573946],\n       [ 0.08581117],\n       [ 0.14957392],\n       [ 0.05518581],\n       [ 0.06217919],\n       [ 0.30812371],\n       [ 0.18145653],\n       [ 0.18202703],\n       [ 0.16765301],\n       [ 0.23545925],\n       [ 0.12351444],\n       [ 0.16428568],\n       [ 0.14631472],\n       [ 0.14683373],\n       [ 0.1745693 ],\n       [ 0.16761852],\n       [ 0.12104839],\n       [ 0.11453046],\n       [ 0.10783504],\n       [ 0.19712032],\n       [ 0.12864024],\n       [ 0.1655966 ],\n       [ 0.22406626],\n       [ 0.12555689],\n       [ 0.08362669],\n       [ 0.09775722],\n       [ 0.14533654],\n       [ 0.26322516],\n       [ 0.132136  ],\n       [ 0.13740652],\n       [ 0.11908082],\n       [ 0.11304895],\n       [ 0.13541609],\n       [ 0.35595952],\n       [ 0.27446025],\n       [ 0.22207496],\n       [ 0.19160455],\n       [ 0.15053126],\n       [ 0.13636141],\n       [ 0.1214855 ],\n       [ 0.17437556],\n       [ 0.17949403],\n       [ 0.24373214],\n       [ 0.13784198],\n       [ 0.16367833],\n       [ 0.12579337],\n       [ 0.2074916 ],\n       [ 0.19749051],\n       [ 0.19482649],\n       [ 0.18014528],\n       [ 0.23689322],\n       [ 0.13081779],\n       [ 0.10756514],\n       [ 0.15280703],\n       [ 0.19973497],\n       [ 0.31314074],\n       [ 0.39241702],\n       [ 0.22245081],\n       [ 0.21265208],\n       [ 0.19318218],\n       [ 0.15987484],\n       [ 0.29265229],\n       [ 0.27084989],\n       [ 0.33995744],\n       [ 0.45050553],\n       [ 0.351743  ],\n       [ 0.18584678],\n       [ 0.20706053],\n       [ 0.45849171],\n       [ 0.61497452],\n       [ 0.26855489],\n       [ 0.28626758],\n       [ 0.24060727],\n       [ 0.24658206],\n       [ 0.23048603],\n       [ 0.46327955],\n       [ 0.36725242],\n       [ 0.40384357],\n       [ 0.38631748],\n       [ 0.35489839],\n       [ 0.2355763 ],\n       [ 0.18443124],\n       [ 0.34458933],\n       [ 0.42659812],\n       [ 0.51786014],\n       [ 0.49938992],\n       [ 0.64039716],\n       [ 0.45623372],\n       [ 0.54931512],\n       [ 0.68629002],\n       [ 0.88418313],\n       [ 1.        ],\n       [ 0.22959474],\n       [ 0.07999218],\n       [ 0.0554716 ],\n       [ 0.04870317],\n       [ 0.07679363],\n       [ 0.07606805],\n       [ 0.20936108],\n       [ 0.22936782],\n       [ 0.60234476],\n       [ 0.36788179],\n       [ 0.35051981],\n       [ 0.67538689],\n       [ 0.85756494],\n       [ 0.79809262],\n       [ 0.65307595],\n       [ 0.50843999],\n       [ 0.25819135],\n       [ 0.33893845],\n       [ 0.73744762],\n       [ 0.61777547],\n       [ 0.42073631],\n       [ 0.49570655],\n       [ 0.36284931],\n       [ 0.28629448],\n       [ 0.34482056],\n       [ 0.68426953],\n       [ 0.58566087],\n       [ 0.71024474],\n       [ 0.70184348],\n       [ 0.44220263],\n       [ 0.37212672],\n       [ 0.28001031],\n       [ 0.52364506],\n       [ 0.54370773],\n       [ 0.46933972],\n       [ 0.58360946],\n       [ 0.39046335],\n       [ 0.24490759],\n       [ 0.24649578],\n       [ 0.51509243],\n       [ 0.44403759],\n       [ 0.38709558],\n       [ 0.35445247],\n       [ 0.32214536],\n       [ 0.29185212],\n       [ 0.27272419],\n       [ 0.34683705],\n       [ 0.44939897],\n       [ 0.36803482],\n       [ 0.3744153 ],\n       [ 0.28652337],\n       [ 0.19015906],\n       [ 0.16439565],\n       [ 0.3193731 ],\n       [ 0.32064995],\n       [ 0.27660945],\n       [ 0.26951804],\n       [ 0.22672662],\n       [ 0.15687619],\n       [ 0.20503834],\n       [ 0.41062979],\n       [ 0.46852336],\n       [ 0.36429847],\n       [ 0.3733447 ],\n       [ 0.25427578],\n       [ 0.20156517],\n       [ 0.12412032],\n       [ 0.19585598],\n       [ 0.3636653 ],\n       [ 0.39402637],\n       [ 0.39744721],\n       [ 0.23931338],\n       [ 0.17530853],\n       [ 0.20778314],\n       [ 0.31591557],\n       [ 0.44229142],\n       [ 0.39884153],\n       [ 0.36475619],\n       [ 0.24088944],\n       [ 0.27216096],\n       [ 0.18981162],\n       [ 0.30664046],\n       [ 0.289768  ],\n       [ 0.31997088],\n       [ 0.32497989],\n       [ 0.22139538],\n       [ 0.14769959],\n       [ 0.14262566],\n       [ 0.33198781],\n       [ 0.33804139],\n       [ 0.26302111],\n       [ 0.19176684],\n       [ 0.11976383],\n       [ 0.18329102],\n       [ 0.30872585],\n       [ 0.3809378 ],\n       [ 0.32458455],\n       [ 0.43023266],\n       [ 0.40422311],\n       [ 0.28579818],\n       [ 0.29193483],\n       [ 0.18050786],\n       [ 0.33223591],\n       [ 0.27923052],\n       [ 0.31132124],\n       [ 0.31972081],\n       [ 0.23316216],\n       [ 0.16836118],\n       [ 0.16139587],\n       [ 0.26194259],\n       [ 0.46914166],\n       [ 0.30309904],\n       [ 0.35294906],\n       [ 0.25185767],\n       [ 0.15679369],\n       [ 0.16411333],\n       [ 0.35333089],\n       [ 0.30457837],\n       [ 0.2801724 ],\n       [ 0.32745934],\n       [ 0.22742097],\n       [ 0.14275883],\n       [ 0.18175918],\n       [ 0.15491697],\n       [ 0.27466345],\n       [ 0.27842568],\n       [ 0.39063865],\n       [ 0.3071294 ],\n       [ 0.18632215],\n       [ 0.30793415],\n       [ 0.37587457],\n       [ 0.36305047],\n       [ 0.33492697],\n       [ 0.33993994],\n       [ 0.21714615],\n       [ 0.17960164],\n       [ 0.1631544 ],\n       [ 0.39839851],\n       [ 0.27411393],\n       [ 0.34315718],\n       [ 0.3468075 ],\n       [ 0.25418121],\n       [ 0.17606759],\n       [ 0.14332331],\n       [ 0.23377423],\n       [ 0.24784051],\n       [ 0.26837324],\n       [ 0.30350429],\n       [ 0.26802029],\n       [ 0.15062862],\n       [ 0.15594721],\n       [ 0.34230284],\n       [ 0.39580215],\n       [ 0.39596922],\n       [ 0.30382924],\n       [ 0.2121517 ],\n       [ 0.1672097 ],\n       [ 0.1993288 ],\n       [ 0.27654678],\n       [ 0.22559521],\n       [ 0.28274085],\n       [ 0.28812938],\n       [ 0.20902763],\n       [ 0.17605013],\n       [ 0.17831252],\n       [ 0.2580778 ],\n       [ 0.34314568],\n       [ 0.4069832 ],\n       [ 0.25617577],\n       [ 0.20931232],\n       [ 0.21076942],\n       [ 0.17477484],\n       [ 0.3891102 ],\n       [ 0.24564907],\n       [ 0.2693887 ],\n       [ 0.28172126],\n       [ 0.18028879],\n       [ 0.12354799],\n       [ 0.14817726],\n       [ 0.38246425],\n       [ 0.22975452],\n       [ 0.2104019 ],\n       [ 0.19106855],\n       [ 0.38580651],\n       [ 0.18827313],\n       [ 0.17205441],\n       [ 0.33873343],\n       [ 0.40697582],\n       [ 0.29428468],\n       [ 0.25048826],\n       [ 0.23582795],\n       [ 0.1575884 ],\n       [ 0.26314848],\n       [ 0.33971892],\n       [ 0.26208386],\n       [ 0.2652514 ],\n       [ 0.26116339],\n       [ 0.24722462],\n       [ 0.2158663 ],\n       [ 0.14668892],\n       [ 0.30460886],\n       [ 0.27046682],\n       [ 0.31505482],\n       [ 0.25486874],\n       [ 0.24909386],\n       [ 0.13756164],\n       [ 0.12565237],\n       [ 0.31635995],\n       [ 0.3135811 ],\n       [ 0.30850481],\n       [ 0.24781108]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('../file/hybrid_total_redeem.csv', index_col='report_date')\n",
    "\n",
    "labels = ['tBalance', 'yBalance', 'total_purchase_amt', 'direct_purchase_amt', 'purchase_bal_amt', 'purchase_bank_amt', 'total_redeem_amt', 'consume_amt', 'transfer_amt', 'tftobal_amt', 'tftocard_amt', 'share_amt']\n",
    "for label in labels:\n",
    "    df[label] = pd.to_numeric(df[label], errors='coerce')\n",
    "dataframe = df['total_redeem_amt']\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float64')\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "\n",
    "dataframe_mulfeature = df[1:]\n",
    "dataset_mulfeature = dataframe_mulfeature.values\n",
    "dataset_mulfeature = dataset_mulfeature.astype('float64')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "dataset = dataset.reshape(-1,1)\n",
    "print(dataset)\n",
    "\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset_mulfeature = scaler2.fit_transform(dataset_mulfeature)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train_x, test_x = dataset_mulfeature[0:train_size,:], dataset_mulfeature[train_size:len(dataset),:]\n",
    "train_y,test_y = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# use this function to prepare the train and test datasets for modeling\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train_x,train_y, look_back)\n",
    "testX, testY = create_dataset(test_x,test_y, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "print(\"trainX\",trainX.shape)\n",
    "print(\"trainY\",trainY.shape)\n",
    "print(\"testX\",testX.shape)\n",
    "print(\"testY\",testY.shape)\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1, 12)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "myfile = os.path.exists(\"lstm.model\")\n",
    "if myfile:\n",
    "    print(\"ssss\")\n",
    "else:\n",
    "    model_prob = model.fit(trainX, trainY, epochs=105, batch_size=1, verbose=2)\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "print('testPredict', testPredict, 'len', len(testPredict))\n",
    "\n",
    "\n",
    "df = pd.read_csv('../file/user_balance_table_all.csv', index_col='user_id', names=['user_id', 'report_date', 'tBalance', 'yBalance', 'total_purchase_amt', 'direct_purchase_amt', 'purchase_bal_amt', 'purchase_bank_amt', 'total_redeem_amt', 'consume_amt', 'transfer_amt', 'tftobal_amt', 'tftocard_amt', 'share_amt', 'category1', 'category2', 'category3', 'category4'\n",
    "], parse_dates=[1])\n",
    "\n",
    "df['report_date'] = pd.to_datetime(df['report_date'], errors='coerce')\n",
    "\n",
    "labels = ['tBalance', 'yBalance', 'total_purchase_amt', 'direct_purchase_amt', 'purchase_bal_amt', 'purchase_bank_amt', 'total_redeem_amt', 'consume_amt', 'transfer_amt', 'tftobal_amt', 'tftocard_amt', 'share_amt']\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    df[label] = pd.to_numeric(df[label], errors='coerce')\n",
    "\n",
    "df = df.groupby('report_date').sum()\n",
    "total_redeem_original = df['total_redeem_amt']\n",
    "\n",
    "len_testPrediction = len(testPredict)\n",
    "testPredict = testPredict.T\n",
    "arima_redeem_prediction = total_redeem_prediction[-len_testPrediction:]\n",
    "hybrid_redeem_prediction_val = arima_redeem_prediction.values + testPredict\n",
    "\n",
    "sub_redeem_original = total_redeem_original[-len_testPrediction:]\n",
    "\n",
    "arima_redeem_prediction.plot(label='predicted')\n",
    "sub_redeem_original.plot(label='original')\n",
    "plt.legend(loc='best')\n",
    "plt.title('ARIMA')\n",
    "plt.show()\n",
    "\n",
    "arima_rmse = err(arima_redeem_prediction.values, sub_redeem_original.values)\n",
    "print('ARIMA RMSE', arima_rmse)\n",
    "\n",
    "hybrid_rmse = err(hybrid_redeem_prediction_val, sub_redeem_original.values)\n",
    "\n",
    "print('Hybrid RMSE', hybrid_rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
